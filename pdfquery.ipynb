{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP4+S5YpdiOgZrcUE7fbEUy"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gCd9DXBvp17Z"
      },
      "outputs": [],
      "source": [
        "!pip install -q cassio datasets langchain openai tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LangChain components to use\n",
        "from langchain.vectorstores.cassandra import Cassandra\n",
        "from langchain.indexes.vectorstore import VectorStoreIndexWrapper\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "\n",
        "# Support for dataset retrieval with Hugging Face\n",
        "from datasets import load_dataset\n",
        "\n",
        "# With CassIO, the engine powering the Astra DB integration in LangChain,\n",
        "# you will also initialize the DB connection:\n",
        "import cassio"
      ],
      "metadata": {
        "id": "CZp56N0NqIkE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyPDF2"
      ],
      "metadata": {
        "id": "__cwtwc_qKlu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PyPDF2 import PdfReader"
      ],
      "metadata": {
        "id": "wAJmVqGeqNnv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ASTRA_DB_APPLICATION_TOKEN = \"\"\n",
        "ASTRA_DB_ID = \"\"\n",
        "\n",
        "OPENAI_API_KEY = \"\""
      ],
      "metadata": {
        "id": "Vfc6g1LPqT_f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pdfreader = PdfReader('test.pdf')"
      ],
      "metadata": {
        "id": "AnzAR3VHqgLH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing_extensions import Concatenate\n",
        "# read text from pdf\n",
        "raw_text = ''\n",
        "for i, page in enumerate(pdfreader.pages):\n",
        "    content = page.extract_text()\n",
        "    if content:\n",
        "        raw_text += content"
      ],
      "metadata": {
        "id": "lN4LLPIsqkPZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_text"
      ],
      "metadata": {
        "id": "jUANQfQ9qmzK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cassio.init(token=ASTRA_DB_APPLICATION_TOKEN, database_id=ASTRA_DB_ID)"
      ],
      "metadata": {
        "id": "bl6zwq6MqoeK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = OpenAI(openai_api_key=OPENAI_API_KEY)\n",
        "embedding = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)"
      ],
      "metadata": {
        "id": "JwzsCs88qzRi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "astra_vector_store = Cassandra(\n",
        "    embedding=embedding,\n",
        "    table_name=\"qa_mini_demo\",\n",
        "    session=None,\n",
        "    keyspace=None,\n",
        ")"
      ],
      "metadata": {
        "id": "htoyWzw9q1VW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "# We need to split the text using Character Text Split such that it sshould not increse token size\n",
        "text_splitter = CharacterTextSplitter(\n",
        "    separator = \"\\n\",\n",
        "    chunk_size = 800,\n",
        "    chunk_overlap  = 200,\n",
        "    length_function = len,\n",
        ")\n",
        "texts = text_splitter.split_text(raw_text)"
      ],
      "metadata": {
        "id": "AsLKFvrxq3v8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts[:50]"
      ],
      "metadata": {
        "id": "twDvu5b9q6Vo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "astra_vector_store.add_texts(texts[:50])\n",
        "\n",
        "print(\"Inserted %i headlines.\" % len(texts[:50]))\n",
        "\n",
        "astra_vector_index = VectorStoreIndexWrapper(vectorstore=astra_vector_store)"
      ],
      "metadata": {
        "id": "CM8OE4IfrBON"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "first_question = True\n",
        "while True:\n",
        "    if first_question:\n",
        "        query_text = input(\"\\nEnter your question (or type 'quit' to exit): \").strip()\n",
        "    else:\n",
        "        query_text = input(\"\\nWhat's your next question (or type 'quit' to exit): \").strip()\n",
        "\n",
        "    if query_text.lower() == \"quit\":\n",
        "        break\n",
        "\n",
        "    if query_text == \"\":\n",
        "        continue\n",
        "\n",
        "    first_question = False\n",
        "\n",
        "    print(\"\\nQUESTION: \\\"%s\\\"\" % query_text)\n",
        "    answer = astra_vector_index.query(query_text, llm=llm).strip()\n",
        "    print(\"ANSWER: \\\"%s\\\"\\n\" % answer)\n",
        "\n",
        "    print(\"FIRST DOCUMENTS BY RELEVANCE:\")\n",
        "    for doc, score in astra_vector_store.similarity_search_with_score(query_text, k=4):\n",
        "        print(\"    [%0.4f] \\\"%s ...\\\"\" % (score, doc.page_content[:84]))"
      ],
      "metadata": {
        "id": "0tEfkvpCrCUa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}